{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hwanda/VMC/VMC.py:654: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if q0 is 0:\n"
     ]
    }
   ],
   "source": [
    "%run 'VMC.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Variational Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Hamiltonian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to study the bilayer honeycomb lattice model:\n",
    "$$H=-\\sum_{\\langle ij\\rangle,l,\\sigma}(c_{il\\sigma}^\\dagger c_{jl\\sigma}+\\text{h.c.})+J\\sum_{i}\\mathbf{S}_{i1}\\cdot\\mathbf{S}_{i2},$$\n",
    "where $\\mathbf{S}_{il}=\\frac{1}{2}c_{il\\alpha}^\\dagger\\mathbf{\\sigma}_{\\alpha\\beta}c_{il\\beta}$. $i$ - site, $l$ - layer, $\\sigma$ - spin. Expectation: strong enough inter-layer Heisenberg coupling $J$ will drive a SMG transition to gap out the Dirac fermions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Ansatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variational ansatz is based on the mean-field Hamiltonian\n",
    "$$H_\\text{MF}[u]=-\\sum_{\\langle ij\\rangle,l,\\sigma}(c_{il\\sigma}^\\dagger c_{jl\\sigma}+\\text{h.c.})+u\\sum_{i,\\sigma}(c_{i1\\sigma}^\\dagger c_{i2\\sigma}+\\text{h.c.}).$$\n",
    "Let $|\\Psi_\\text{MF}[u]\\rangle$ be the ground state of $H_\\text{MF}[u]$, the variational state is\n",
    "$$|\\Psi\\rangle=\\mathcal{P}[E]|\\Psi_\\text{MF}[u]\\rangle,$$\n",
    "where the projection operator suppress the inter-layer charge fluctuation\n",
    "$$\\mathcal{P}[E]=\\mathcal{P}_\\text{global}\\exp\\left(-\\sum_i E(\\mathbf{q}_i)\\right).$$\n",
    "The charge vector on each site may include the total charge, the valey charge and the spin:\n",
    "$$\\mathbf{q}_i=\\sum_{l,\\sigma}(1,(-)^l,(-)^\\sigma) n_{il\\sigma}$$\n",
    "with $n_{il\\sigma}=c_{il\\sigma}^\\dagger c_{il\\sigma}$. $\\mathcal{P}_\\text{global}$ is the additional symmetry projection operator to ensure global symmetry charge neutrality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let ${|x\\rangle}_{x\\in X}$ be a complete basis of the many-body Hilbert space (with total electric charge and total valley charge neutral). The expectation value of any observable $O$ can be written as\n",
    "$$\\langle O\\rangle=\\frac{\\langle \\Psi|O|\\Psi\\rangle}{\\langle\\Psi|\\Psi\\rangle}=\\sum_{x}O(x)p(x),$$\n",
    "with\n",
    "$$O(x)=\\frac{\\langle \\Psi|O|x\\rangle}{\\langle \\Psi|x\\rangle}=\\sum_{x'}\\frac{\\langle \\Psi|x'\\rangle}{\\langle \\Psi|x\\rangle}\\langle x'|O|x\\rangle,$$\n",
    "$$p(x)=\\frac{|\\langle \\Psi|x\\rangle|^2}{\\sum_{x}|\\langle \\Psi|x\\rangle|^2}.$$\n",
    "\n",
    "To sample from $p(x)$, following the Markov chain with the transition probability\n",
    "$$p(x'|x)=\\frac{p(x')}{p(x)}=\\left|\\frac{\\langle \\Psi|x'\\rangle}{\\langle \\Psi|x\\rangle}\\right|^2.$$\n",
    "\n",
    "The many-body basis $|x\\rangle$ is choosen to be the eigen basis of the projection operator $\\mathcal{P}[g]$, such that the amplitude ratio can be evaluated as\n",
    "$$\\frac{\\langle \\Psi|x'\\rangle}{\\langle \\Psi|x\\rangle}=\\frac{\\langle \\Psi_\\text{MF}[u]|x'\\rangle}{\\langle \\Psi_\\text{MF}[u]|x\\rangle}\\frac{\\langle x'|\\mathcal{P}[E]|x'\\rangle}{\\langle x|\\mathcal{P}[E]|x\\rangle}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective function (minimize) (let $\\theta$ be the parameter for $|{\\Psi}\\rangle$):\n",
    "$$\\langle H\\rangle_\\theta=\\sum_{x}H_\\theta(x)p_\\theta(x),$$\n",
    "Differetial programming:\n",
    "$$\\begin{split}\n",
    "\\partial_\\theta \\langle H\\rangle_\\theta&=\\sum_{x}\\partial_\\theta H_\\theta(x)p_\\theta(x)+H_\\theta(x) \\partial_\\theta p_\\theta(x)\\\\\n",
    "&=\\sum_{x}\\partial_\\theta H_\\theta(x)p_\\theta(x)+H_\\theta(x) \\frac{\\partial_\\theta p_\\theta(x)}{ p_\\theta(x)} p_\\theta(x)\\\\\n",
    "&=\\sum_{x}(\\partial_\\theta H_\\theta(x)+H_\\theta(x) \\partial_\\theta \\ln p_\\theta(x))p_\\theta(x)\n",
    "\\end{split}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lattice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deform the honeycomb lattice to a square lattice, such that $x,y=0,\\cdots,L-1$.\n",
    "\n",
    "<img src=\"lattice.png\" width=180>\n",
    "\n",
    "red - sublattice A $(x,y)$, blue - sublattice B $(x+\\frac{1}{2},y+\\frac{1}{2})$. Assume periodic boundary condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: create a honeycomb lattice size $L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "latt = HoneycombModel(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lattice sites and their corresponding site indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 0), (0, 0, 1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(latt.sites())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lattice bonds (pairs of site indices) and their corresponding bound strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 0, 0), (0, 0, 1), 1.0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(latt.bonds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{((0, 4),): 1.0,\n",
       " ((4, 0),): 1.0,\n",
       " ((1, 5),): 1.0,\n",
       " ((5, 1),): 1.0,\n",
       " ((2, 6),): 1.0,\n",
       " ((6, 2),): 1.0,\n",
       " ((3, 7),): 1.0,\n",
       " ((7, 3),): 1.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latt.Ht().terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fermion occupation configruation is specified by a subset of modes. The configuration class is inherated from the list class, but with additional dictionary to track the index of each mode in the list. Modes should not duplicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 7, 4, 2]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Configuration([1,3,7,4,2])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if a mode is contained in the configuration. $O(1)$ complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 in x, 5 in x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration is treated as a list and can be used to index Torch tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4082, 0.3264, 0.3156, 0.4925],\n",
       "        [0.3501, 0.9738, 0.9768, 0.7121],\n",
       "        [0.6714, 0.2511, 0.9985, 0.2498],\n",
       "        [0.6490, 0.6743, 0.5948, 0.5691],\n",
       "        [0.0378, 0.6525, 0.0409, 0.2165]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(8,4)[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a independent copy, such that updating the new copy will not affect the old one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 3, 7, 4, 2], [5, 3, 7, 4, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = x.clone()\n",
    "x1[0] = 5\n",
    "x, x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mode replacement can be implemented by `.replace(source, target)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3, 7, 4, 8]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.replace(2,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invalid replacemenet leads to `ConfigurationError`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConfigurationError",
     "evalue": "Mode 7 can not be created in the configuration.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConfigurationError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1m/3nz1kxmj2mgb2s2gwq2ndxqh0000gn/T/ipykernel_1393/1866635799.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfiguration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox (Personal)/Projects/[You]SMG/VMC/VMC.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, mode_src, mode_tgt)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeidx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode_tgt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_tgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode_tgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (Personal)/Projects/[You]SMG/VMC/VMC.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'created'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConfigurationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConfigurationError\u001b[0m: Mode 7 can not be created in the configuration."
     ]
    }
   ],
   "source": [
    "x = Configuration([1,3,7,4,2])\n",
    "x.replace(3,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basis System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basis system manages many-body basis and their charge assignment. Each basis state $|{x}\\rangle$ is labeled by an occupation configuration $x$ (which is a subset of modes that are occupied)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: random sampling a configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 'VMC.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 2, 3]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = BasisSystem(latt)\n",
    "x = bs.sample()\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charge vector on each site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2,  0],\n",
       "        [ 2,  0]])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.qi(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.qmsk(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.qmsk(x, q0=torch.tensor([2.,0.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean-Field Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "latt = HoneycombModel(1)\n",
    "mf = MeanfieldModel(latt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0., -0., -1., -0., -1., -0., -0., -0.],\n",
       "        [-0., -0., -0., -1., -0., -1., -0., -0.],\n",
       "        [-1., -0., -0., -0., -0., -0., -1., -0.],\n",
       "        [-0., -1., -0., -0., -0., -0., -0., -1.],\n",
       "        [-1., -0., -0., -0., -0., -0.,  1., -0.],\n",
       "        [-0., -1., -0., -0., -0., -0., -0.,  1.],\n",
       "        [-0., -0., -1., -0.,  1., -0., -0., -0.],\n",
       "        [-0., -0., -0., -1., -0.,  1., -0., -0.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, -0.7071,  0.0000,  0.0000],\n",
       "        [ 0.1838,  0.0000, -0.5500,  0.4047],\n",
       "        [-0.1926, -0.5000, -0.3135, -0.3386],\n",
       "        [-0.3128, -0.0000, -0.3667,  0.5174],\n",
       "        [ 0.1926, -0.5000,  0.3135,  0.3386],\n",
       "        [ 0.5727, -0.0000, -0.4111,  0.0549],\n",
       "        [-0.2723, -0.0000, -0.4433, -0.4789],\n",
       "        [-0.6262, -0.0000,  0.0314,  0.3270]], grad_fn=<CloneBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ProjectorModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hwanda/VMC/VMC.py:589: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if q0 is 0:\n"
     ]
    }
   ],
   "source": [
    "%run \"VMC.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.3944, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pj = ProjectorModel()\n",
    "pj.energy(bs.qi(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.1972, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pj.energy(torch.tensor([[1,0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variational model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = VariationalModel(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a variational state configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(VariationalState([4, 1, 2, 7]),\n",
       " tensor(-0.2500, grad_fn=<MulBackward0>),\n",
       " tensor([[0., 0.],\n",
       "         [0., 0.]], dtype=torch.float64),\n",
       " tensor([[ 7.0711e-01, -3.4110e-08, -7.0711e-01,  1.0012e-08],\n",
       "         [-2.9802e-08,  1.0000e+00, -2.9802e-08,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  1.0000e+00, -1.4901e-08],\n",
       "         [-8.9407e-08, -7.0711e-01, -8.9407e-08,  7.0711e-01],\n",
       "         [ 1.0000e+00,  0.0000e+00,  2.9802e-08, -2.9802e-08],\n",
       "         [-6.3330e-08,  7.0711e-01, -6.3330e-08,  7.0711e-01],\n",
       "         [ 7.0711e-01,  2.9802e-08,  7.0711e-01,  5.9605e-08],\n",
       "         [-2.9802e-08,  0.0000e+00, -2.9802e-08,  1.0000e+00]],\n",
       "        grad_fn=<MmBackward0>))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = mdl.state([4,1,2,7])\n",
    "st, st.det, st.qi, st.W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward the state configuration by a sequence of instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(VariationalState([4, 3, 0, 7]),\n",
       " tensor(-0.1250, grad_fn=<MulBackward0>),\n",
       " tensor([[0., 0.],\n",
       "         [0., 0.]], dtype=torch.float64),\n",
       " tensor([[ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00],\n",
       "         [-3.1249e-07, -1.4142e+00,  2.2096e-07,  1.0000e+00],\n",
       "         [ 1.0000e+00,  6.8221e-08, -1.4142e+00, -4.8982e-08],\n",
       "         [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 1.0000e+00,  2.0331e-15, -4.2147e-08, -2.9802e-08],\n",
       "         [-3.0547e-07, -1.0000e+00,  2.1600e-07,  1.4142e+00],\n",
       "         [ 1.4142e+00,  6.0927e-09, -1.0000e+00,  6.5308e-08],\n",
       "         [-5.9605e-08, -2.0331e-15,  4.2147e-08,  1.0000e+00]],\n",
       "        grad_fn=<CopySlices>))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st1 = st.forward([(1,3),(2,0)])\n",
    "st1, st1.det, st1.qi, st1.W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward the state configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(VariationalState([4, 1, 2, 7]),\n",
       " tensor(-0.2500, grad_fn=<MulBackward0>),\n",
       " tensor([[0., 0.],\n",
       "         [0., 0.]], dtype=torch.float64),\n",
       " tensor([[ 7.0711e-01, -3.4110e-08, -7.0711e-01, -5.2517e-10],\n",
       "         [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00],\n",
       "         [-1.1048e-07, -7.0711e-01, -1.1048e-07,  7.0711e-01],\n",
       "         [ 1.0000e+00,  0.0000e+00,  2.9802e-08, -2.9802e-08],\n",
       "         [-4.2257e-08,  7.0711e-01, -4.2257e-08,  7.0711e-01],\n",
       "         [ 7.0711e-01,  2.9802e-08,  7.0711e-01,  7.0141e-08],\n",
       "         [-2.9802e-08,  0.0000e+00, -2.9802e-08,  1.0000e+00]],\n",
       "        grad_fn=<CopySlices>))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st2 = st1.backward([(1,3),(2,0)])\n",
    "st2, st2.det, st2.qi, st2.W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invalid instruction leads to error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConfigurationError",
     "evalue": "Mode 3 can not be annihilated in the configuration.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConfigurationError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1m/3nz1kxmj2mgb2s2gwq2ndxqh0000gn/T/ipykernel_1393/1499959323.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox (Personal)/Projects/[You]SMG/VMC/VMC.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, instruction)\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_tgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConfigurationError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (Personal)/Projects/[You]SMG/VMC/VMC.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, instruction)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmode_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_tgt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minstruction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                 \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_tgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConfigurationError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (Personal)/Projects/[You]SMG/VMC/VMC.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, mode_src, mode_tgt)\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeidx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode_src\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConfigurationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'annihilated'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode_src\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode_src\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmode_tgt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmode_tgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConfigurationError\u001b[0m: Mode 3 can not be annihilated in the configuration."
     ]
    }
   ],
   "source": [
    "st.forward([(3,4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variational model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = VariationalModel(1)\n",
    "st = mdl.state([0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(VariationalState([0, 5, 2, 3]),\n",
       " tensor(1.0986, dtype=torch.float64),\n",
       " tensor(0.6931, dtype=torch.float64, grad_fn=<SubBackward0>))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st1, logq = mdl.propose2(st)\n",
    "st1, logq, st1.logprob - st.logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]     25  0.027\n",
      "[0, 1, 2, 7]     48  0.054\n",
      "[0, 1, 3, 6]     56  0.054\n",
      "[0, 1, 6, 7]     96  0.108\n",
      "[0, 2, 3, 5]     66  0.054\n",
      "[0, 2, 5, 7]     21  0.027\n",
      "[0, 3, 5, 6]    107  0.108\n",
      "[0, 5, 6, 7]     46  0.054\n",
      "[1, 2, 3, 4]     49  0.054\n",
      "[1, 2, 4, 7]     88  0.108\n",
      "[1, 2, 5, 6]     30  0.027\n",
      "[1, 3, 4, 6]     38  0.027\n",
      "[1, 4, 6, 7]     59  0.054\n",
      "[2, 3, 4, 5]    132  0.108\n",
      "[2, 4, 5, 7]     43  0.054\n",
      "[3, 4, 5, 6]     66  0.054\n",
      "[4, 5, 6, 7]     31  0.027\n"
     ]
    }
   ],
   "source": [
    "configs = [sorted(st.config)]\n",
    "for _ in range(1000):\n",
    "    st, _ = mdl.MCstep(st)\n",
    "    configs.append(sorted(st.config))\n",
    "configs, counts = torch.unique(torch.tensor(configs), return_counts=True, dim=0)\n",
    "ps = torch.stack([mdl.state(config.tolist()).logprob.exp() for config in configs])\n",
    "ps = ps/ ps.sum()\n",
    "for config, count, p in zip(configs, counts, ps):\n",
    "    print('{} {:6d} {:6.3f}'.format(config.tolist(), count.item(), p.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hwanda/VMC/VMC.py:589: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if q0 is 0:\n"
     ]
    }
   ],
   "source": [
    "%run 'VMC.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0000, 0.0008, 0.0008,\n",
       "         0.0008, 0.0008, 0.0000, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008],\n",
       "        dtype=torch.float64, grad_fn=<StackBackward0>),\n",
       " tensor(0.0123, dtype=torch.float64, grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = VariationalModel(1)\n",
    "mdl.meanfield.u = torch.nn.Parameter(torch.tensor(0.))\n",
    "ps = torch.stack([mdl.state(config.tolist()).logprob.exp() for config in configs])\n",
    "ps, ps.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rejection rate is low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mdl._rejects/ mdl._step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{((0, 0), (2, 2)): 0.25,\n",
       " ((0, 0), (3, 3)): -0.25,\n",
       " ((1, 1), (2, 2)): -0.25,\n",
       " ((1, 1), (3, 3)): 0.25,\n",
       " ((0, 2), (3, 1)): -0.5,\n",
       " ((2, 0), (1, 3)): -0.5,\n",
       " ((4, 6), (7, 5)): -0.5,\n",
       " ((6, 4), (5, 7)): -0.5,\n",
       " ((4, 4), (6, 6)): 0.25,\n",
       " ((4, 4), (7, 7)): -0.25,\n",
       " ((5, 5), (6, 6)): -0.25,\n",
       " ((5, 5), (7, 7)): 0.25,\n",
       " ((0, 4),): -1.0,\n",
       " ((4, 0),): -1.0,\n",
       " ((1, 5),): -1.0,\n",
       " ((5, 1),): -1.0,\n",
       " ((2, 6),): -1.0,\n",
       " ((6, 2),): -1.0,\n",
       " ((3, 7),): -1.0,\n",
       " ((7, 3),): -1.0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = VariationalModel(1)\n",
    "st = mdl.state([0,1,2,3])\n",
    "op = - mdl.lattice.Ht + mdl.lattice.HJ\n",
    "op.terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaulate $O(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.6569, dtype=torch.float64, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.evaluate(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hwanda/VMC/VMC.py:665: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if q0 is 0:\n"
     ]
    }
   ],
   "source": [
    "%run 'VMC.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mdl = VariationalModel(1)\n",
    "H = - mdl.lattice.Ht + 5*mdl.lattice.HJ\n",
    "state = mdl.MCrun(steps=10).reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(mdl.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.1164499269370554 -1.1164499269370554\n",
      "-0.9709138219583201 -0.9709138219583201\n",
      "-1.095825029053172 -1.095825029053172\n",
      "-0.958490807643851 -0.958490807643851\n",
      "-0.9325108321900876 -0.9325108321900876\n",
      "-1.1173666922735825 -1.1173666922735825\n",
      "-0.9744966948882666 -0.9744966948882666\n",
      "-0.9829344810533547 -0.9829344810533547\n",
      "-0.9040803966375979 -0.9040803966375979\n",
      "-0.9122904338789626 -0.9122904338789626\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(10):\n",
    "    Hval, state = mdl.MCrun(H=H, state=state, steps=100)\n",
    "    loss = Hval #- Hval.detach()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    mdl.reset()\n",
    "    state.reset()\n",
    "    print('{} {}'.format(loss.item()/5, Hval.item()/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3] 0.1969028838557125\n",
      "[0, 1, 2, 7] 0.22103719317402273\n",
      "[0, 1, 3, 6] 0.22103719317402273\n",
      "[0, 1, 6, 7] 0.29306304792012655\n",
      "[0, 2, 3, 5] 0.22103719317402273\n",
      "[0, 2, 5, 7] 0.16128398269895833\n",
      "[0, 3, 4, 7] 0.1608896898826247\n",
      "[0, 3, 5, 6] 0.35779257373833717\n",
      "[0, 5, 6, 7] 0.22103719317402284\n",
      "[1, 2, 3, 4] 0.22103719317402265\n",
      "[1, 2, 4, 7] 0.35779257373833717\n",
      "[1, 2, 5, 6] 0.1608896898826247\n",
      "[1, 3, 4, 6] 0.16128398269895847\n",
      "[1, 4, 6, 7] 0.22103719317402273\n",
      "[2, 3, 4, 5] 0.29306304792012644\n",
      "[2, 4, 5, 7] 0.22103719317402265\n",
      "[3, 4, 5, 6] 0.22103719317402273\n",
      "[4, 5, 6, 7] 0.19690288385571245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-5.3593, dtype=torch.float64, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs = [[0, 1, 2, 3],\n",
    " [0, 1, 2, 7],\n",
    " [0, 1, 3, 6],\n",
    " [0, 1, 6, 7],\n",
    " [0, 2, 3, 5],\n",
    " [0, 2, 5, 7],\n",
    " [0, 3, 4, 7],\n",
    " [0, 3, 5, 6],\n",
    " [0, 5, 6, 7],\n",
    " [1, 2, 3, 4],\n",
    " [1, 2, 4, 7],\n",
    " [1, 2, 5, 6],\n",
    " [1, 3, 4, 6],\n",
    " [1, 4, 6, 7],\n",
    " [2, 3, 4, 5],\n",
    " [2, 4, 5, 7],\n",
    " [3, 4, 5, 6],\n",
    " [4, 5, 6, 7]]\n",
    "ps = []\n",
    "Hval = 0\n",
    "for config in configs:\n",
    "    ps.append(mdl.state(config).logprob.exp().item())\n",
    "ampls = [(float(p)/sum(ps)) ** 0.5 for p in ps]\n",
    "for config, ampl in zip(configs, ampls):\n",
    "    print('{} {}'.format(config, ampl))\n",
    "    Hval += H.evaluate(mdl.state(config)) * ampl**2\n",
    "Hval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor(2.2140, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0573,  0.0941, -0.0437],\n",
       "         [-0.1131,  0.0941,  0.0722]], requires_grad=True))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.meanfield.u, mdl.projector.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(VariationalState([4, 5, 6, 3]),\n",
       " tensor([[-1, -1],\n",
       "         [ 1,  1]]),\n",
       " tensor(4.0621, grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state, state.qi, state.energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EigVecsH(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, A, UPLO, tol):\n",
    "        L, Q = torch.linalg.eigh(A, UPLO=UPLO)\n",
    "        ctx.save_for_backward(Q)\n",
    "        ctx.L = L\n",
    "        ctx.requires_grad_A = A.requires_grad\n",
    "        ctx.tol = tol\n",
    "        return Q\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_Q):\n",
    "        (Q,) = ctx.saved_tensors\n",
    "        if ctx.requires_grad_A:\n",
    "            QH = Q.T.conj()\n",
    "            G = QH.mm(grad_Q)\n",
    "            G = (G - G.T.conj())/2\n",
    "            dL = ctx.L.unsqueeze(0) - ctx.L.unsqueeze(1)\n",
    "            F = dL / (dL**2 + ctx.tol**2)\n",
    "            grad_A = Q.mm(G * F).mm(QH)\n",
    "            return grad_A, None, None\n",
    "        else:\n",
    "            return None, None, None\n",
    "        \n",
    "def eigvecsh(A, UPLO='L', tol=1.e-10):\n",
    "    return EigVecsH.apply(A, UPLO, tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[0.,1.],[1.,0.]])\n",
    "Z = torch.tensor([[1.,0.],[0.,-1.]])\n",
    "I = torch.tensor([[1.,0.],[0.,1.]])\n",
    "X = torch.kron(X, I)\n",
    "Z = torch.kron(Z, I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: \n",
      " tensor([[-4., -0., -3., -0.],\n",
      "        [-0., -4., -0., -3.],\n",
      "        [-3., -0.,  4.,  0.],\n",
      "        [-0., -3.,  0.,  4.]], grad_fn=<SubBackward0>)\n",
      "U: \n",
      " tensor([[-0.9487, -0.0000,  0.0000, -0.3162],\n",
      "        [ 0.0000, -0.9487, -0.3162,  0.0000],\n",
      "        [-0.3162,  0.0000,  0.0000,  0.9487],\n",
      "        [-0.0000, -0.3162,  0.9487,  0.0000]], grad_fn=<EigVecsHBackward>)\n",
      "M: \n",
      " tensor([[-0.9487, -0.0000],\n",
      "        [ 0.0000, -0.9487],\n",
      "        [-0.3162,  0.0000],\n",
      "        [-0.0000, -0.3162]], grad_fn=<SliceBackward0>)\n",
      "x: \n",
      " tensor(1.2000, grad_fn=<TraceBackward0>) \n",
      "z: \n",
      " tensor(1.6000, grad_fn=<TraceBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.2560), tensor(-0.1920))"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(3.).requires_grad_() \n",
    "b = torch.tensor(4.).requires_grad_() \n",
    "A = - a*X - b*Z\n",
    "print('A: \\n',A)\n",
    "U = eigvecsh(A, tol=1.e-5)\n",
    "print('U: \\n',U)\n",
    "M = U[:,:(A.shape[-1]//2)]\n",
    "print('M: \\n',M)\n",
    "x = M.T.conj().mm(X).mm(M).trace()\n",
    "z = M.T.conj().mm(Z).mm(M).trace()\n",
    "print('x: \\n', x, '\\nz: \\n', z)\n",
    "x.backward()\n",
    "a.grad, b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdateW(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, W, mode_tgt, idx):\n",
    "        ratio = W[mode_tgt, idx].clone()\n",
    "        Wcol = W[:, idx].clone()\n",
    "        Wrow = W[mode_tgt, :].clone()\n",
    "        Wrow[idx] -= 1.\n",
    "        ctx.need_grad = W.requires_grad\n",
    "        if ctx.need_grad:\n",
    "            ctx.mode_tgt, ctx.idx, ctx.ratio, ctx.Wcol, ctx.Wrow = mode_tgt, idx, ratio, Wcol, Wrow\n",
    "        return W - Wrow.unsqueeze(0) * Wcol.unsqueeze(1) / ratio\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_W):\n",
    "        grad_Wout = None\n",
    "        if ctx.need_grad:\n",
    "            grad_Wcol = grad_W @ ctx.Wrow / ctx.ratio\n",
    "            grad_Wrow = ctx.Wcol @ grad_W / ctx.ratio\n",
    "            grad_ratio = grad_Wrow @ ctx.Wrow / ctx.ratio\n",
    "            grad_Wout = grad_W.clone()\n",
    "            grad_Wout[:, ctx.idx] -= grad_Wcol\n",
    "            grad_Wout[ctx.mode_tgt, :] -= grad_Wrow\n",
    "            grad_Wout[ctx.mode_tgt, ctx.idx] += grad_ratio\n",
    "        return grad_Wout, None, None\n",
    "    \n",
    "updateW = UpdateW.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 4.7706e-18,  1.0000e+00,  5.7582e-18,  0.0000e+00],\n",
       "        [ 0.0000e+00, -5.2155e-18,  1.0000e+00,  0.0000e+00],\n",
       "        [ 6.4585e-17, -7.0711e-01,  8.1220e-17,  7.0711e-01],\n",
       "        [ 1.4142e+00,  3.0709e-16,  1.0000e+00,  0.0000e+00],\n",
       "        [ 7.4192e-17,  7.0711e-01,  9.9191e-17,  7.0711e-01],\n",
       "        [ 1.0000e+00,  5.2736e-16,  1.4142e+00,  3.9252e-17],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       "       dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W0 = VariationalModel(1).state([0,1,2,7]).W.detach().requires_grad_()\n",
    "W0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-3.3727e-18,  1.0000e+00,  5.7582e-18,  0.0000e+00],\n",
       "        [-1.4142e+00, -3.1231e-16,  1.0000e+00,  0.0000e+00],\n",
       "        [-5.0277e-17, -7.0711e-01,  8.1220e-17,  7.0711e-01],\n",
       "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00],\n",
       "        [-6.6085e-17,  7.0711e-01,  9.9191e-17,  7.0711e-01],\n",
       "        [-1.0000e+00,  9.3065e-17,  1.4142e+00,  3.9252e-17],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       "       dtype=torch.float64, grad_fn=<UpdateWBackward>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = updateW(W0, 4, 2)\n",
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    for j in range(4):\n",
    "        def func(W):\n",
    "            return updateW(W, 4, 2)[i,j]\n",
    "        print(torch.autograd.gradcheck(func, W0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 0],\n",
       "        [2, 0]])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = qi.abs()\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4076, -1.4076, -0.4076],\n",
       "        [-1.0986, -1.0986, -1.0986]])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = torch.tensor([[0.,1.,2.],[0.,0.,0.]])\n",
    "mu = torch.nn.functional.log_softmax(weight,-1)\n",
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.8152), tensor(-2.1972))"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu[0,idx[:,0]].sum() + mu[1,idx[:,1]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.0124)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mu[i,idx[:,i]].sum() for i in range(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train two-site model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hwanda/VMC/VMC.py:651: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if q0 is 0:\n"
     ]
    }
   ],
   "source": [
    "%run 'VMC.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### exact optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0303394841464057\n",
      "-1.5102617270809378\n",
      "-1.545729838645621\n",
      "-1.5549012616987408\n",
      "-1.5587296836661937\n",
      "-1.5606989130978626\n",
      "-1.5618387217340817\n",
      "-1.5625504929276506\n",
      "-1.5630193402339474\n",
      "-1.5633406213842143\n",
      "-1.5635674679493812\n",
      "-1.5637313545232605\n",
      "-1.5638518367941572\n",
      "-1.5639415652776505\n",
      "-1.564009023779518\n",
      "-1.5640600865923464\n",
      "-1.5640988872628436\n",
      "-1.5641284250801089\n",
      "-1.5641509252948074\n",
      "-1.5641680372866469\n",
      "-1.5641810167640993\n",
      "-1.564190813616637\n",
      "-1.5641981790576067\n",
      "-1.5642036728856605\n",
      "-1.5642077257616793\n",
      "-1.5642107067181874\n",
      "-1.5642128670444875\n",
      "-1.564214410558721\n",
      "-1.5642155012317032\n",
      "-1.5642162622627187\n",
      "-1.564216784144059\n"
     ]
    }
   ],
   "source": [
    "configs = [[0, 1, 2, 3],\n",
    " [0, 1, 2, 7],\n",
    " [0, 1, 3, 6],\n",
    " [0, 1, 6, 7],\n",
    " [0, 2, 3, 5],\n",
    " [0, 2, 5, 7],\n",
    " [0, 3, 4, 7],\n",
    " [0, 3, 5, 6],\n",
    " [0, 5, 6, 7],\n",
    " [1, 2, 3, 4],\n",
    " [1, 2, 4, 7],\n",
    " [1, 2, 5, 6],\n",
    " [1, 3, 4, 6],\n",
    " [1, 4, 6, 7],\n",
    " [2, 3, 4, 5],\n",
    " [2, 4, 5, 7],\n",
    " [3, 4, 5, 6],\n",
    " [4, 5, 6, 7]]\n",
    "\n",
    "mdl = VariationalModel(1)\n",
    "H = - 0.2 * mdl.lattice.Ht + mdl.lattice.HJ\n",
    "optimizer = torch.optim.Adam(mdl.parameters(), lr = 0.01)\n",
    "\n",
    "for _ in range(3000):\n",
    "    Hval ,configs = mdl.exct_run(H=H,configs=configs)\n",
    "    loss = Hval\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    mdl.reset()\n",
    "    if _ % 99 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3] -0.03643906529819733\n",
      "[0, 1, 2, 7] -0.07801323630820518\n",
      "[0, 1, 3, 6] 0.07801323630820516\n",
      "[0, 1, 6, 7] -0.03990479588956507\n",
      "[0, 2, 3, 5] -0.07801323630820525\n",
      "[0, 2, 5, 7] 0.030222788062085105\n",
      "[0, 3, 4, 7] 0.4671453929326423\n",
      "[0, 3, 5, 6] -0.5035844582308399\n",
      "[0, 5, 6, 7] -0.07801323630820525\n",
      "[1, 2, 3, 4] 0.07801323630820511\n",
      "[1, 2, 4, 7] -0.5035844582308392\n",
      "[1, 2, 5, 6] 0.46714539293264207\n",
      "[1, 3, 4, 6] 0.030222788062085077\n",
      "[1, 4, 6, 7] 0.07801323630820518\n",
      "[2, 3, 4, 5] -0.039904795889565074\n",
      "[2, 4, 5, 7] -0.07801323630820518\n",
      "[3, 4, 5, 6] 0.07801323630820522\n",
      "[4, 5, 6, 7] -0.03643906529819733\n",
      "energy = -1.564216908158246 normalization factor = 0.01047977322417201 fidelity = 0.9877903667806816\n"
     ]
    }
   ],
   "source": [
    "test(H, mdl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### \"agent free\" policy gradient optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### return plcy=0 for rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward = 0.42676827757349756 enery = -0.8930184694319778 rejection rate = 0.05454545454545454\n",
      "reward = 0.6380398217149059 enery = -1.4323707713128098 rejection rate = 0.13\n",
      "reward = 0.6515165289061414 enery = -1.5586111348420872 rejection rate = 0.17\n",
      "reward = 0.69483742085273 enery = -1.6066518659391542 rejection rate = 0.15\n",
      "reward = 0.6765860597664118 enery = -1.55037837165495 rejection rate = 0.14\n",
      "reward = 0.7557252879235208 enery = -1.6091763237857473 rejection rate = 0.07\n"
     ]
    }
   ],
   "source": [
    "mdl = VariationalModel(1)\n",
    "H = -0.2* mdl.lattice.Ht + mdl.lattice.HJ\n",
    "state = mdl.MCrun(steps=10).reset()\n",
    "optimizer = torch.optim.Adam(mdl.parameters(), lr=0.01)\n",
    "\n",
    "for iteration in range(500):\n",
    "    rwd, Hval, state = mdl.MCrun_pg(H=H, state=state, steps=100)\n",
    "    loss = rwd\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if iteration % 99 ==0:\n",
    "        print('reward =', - loss.item(),'enery =', Hval.item(), 'rejection rate =',mdl._rejects/mdl._step)\n",
    "    mdl.reset()\n",
    "    state.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3] -0.09546592161198394\n",
      "[0, 1, 2, 7] -0.10894306799040362\n",
      "[0, 1, 3, 6] 0.10894306799040362\n",
      "[0, 1, 6, 7] -0.0764293610349696\n",
      "[0, 2, 3, 5] -0.10894306799040358\n",
      "[0, 2, 5, 7] 0.041784150541509676\n",
      "[0, 3, 4, 7] 0.41663093529211453\n",
      "[0, 3, 5, 6] -0.5120968569040982\n",
      "[0, 5, 6, 7] -0.10894306799040358\n",
      "[1, 2, 3, 4] 0.10894306799040362\n",
      "[1, 2, 4, 7] -0.5120968569040983\n",
      "[1, 2, 5, 6] 0.41663093529211437\n",
      "[1, 3, 4, 6] 0.041784150541509676\n",
      "[1, 4, 6, 7] 0.10894306799040358\n",
      "[2, 3, 4, 5] -0.07642936103496958\n",
      "[2, 4, 5, 7] -0.10894306799040358\n",
      "[3, 4, 5, 6] 0.10894306799040358\n",
      "[4, 5, 6, 7] -0.0954659216119839\n",
      "energy = -1.5405187276607923 normalization factor = 0.014774703008139357 fidelity = 0.9716204785817014\n"
     ]
    }
   ],
   "source": [
    "test(H, mdl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### return plcy=-p(x')/p(x)+p(x') for rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward = 0.33505532914754177 enery = -0.8288763338082471 rejection rate = 0.1\n",
      "reward = 0.3252004631121784 enery = -1.017348096860554 rejection rate = 0.38\n",
      "reward = 0.5463910528339057 enery = -1.398356522333816 rejection rate = 0.2\n",
      "reward = 0.5533694198627749 enery = -1.4362776634059762 rejection rate = 0.22\n",
      "reward = 0.40250878012142555 enery = -0.9701075496788516 rejection rate = 0.44\n",
      "reward = 0.5005185707466694 enery = -1.324474896834815 rejection rate = 0.24\n"
     ]
    }
   ],
   "source": [
    "mdl = VariationalModel(1)\n",
    "H = -0.2* mdl.lattice.Ht + mdl.lattice.HJ\n",
    "state = mdl.MCrun(steps=10).reset()\n",
    "optimizer = torch.optim.Adam(mdl.parameters(), lr=0.01)\n",
    "\n",
    "for iteration in range(500):\n",
    "    rwd, Hval, state = mdl.MCrun_pg(H=H, state=state, steps=100)\n",
    "    loss = rwd\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if iteration % 99 ==0:\n",
    "        print('reward =', - loss.item(),'enery =', Hval.item(), 'rejection rate =',mdl._rejects/mdl._step)\n",
    "    mdl.reset()\n",
    "    state.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3] -0.14556121792538101\n",
      "[0, 1, 2, 7] -0.03690893583172228\n",
      "[0, 1, 3, 6] 0.03690893583172228\n",
      "[0, 1, 6, 7] -0.0115016628302367\n",
      "[0, 2, 3, 5] -0.036908935831722264\n",
      "[0, 2, 5, 7] 0.047460729683313344\n",
      "[0, 3, 4, 7] 0.40700268090225783\n",
      "[0, 3, 5, 6] -0.5525638988276386\n",
      "[0, 5, 6, 7] -0.03690893583172228\n",
      "[1, 2, 3, 4] 0.036908935831722264\n",
      "[1, 2, 4, 7] -0.5525638988276388\n",
      "[1, 2, 5, 6] 0.4070026809022577\n",
      "[1, 3, 4, 6] 0.047460729683313344\n",
      "[1, 4, 6, 7] 0.03690893583172228\n",
      "[2, 3, 4, 5] -0.011501662830236693\n",
      "[2, 4, 5, 7] -0.03690893583172228\n",
      "[3, 4, 5, 6] 0.036908935831722264\n",
      "[4, 5, 6, 7] -0.1455612179253811\n",
      "energy = -1.457724020349126 normalization factor = 0.033635787728758415 fidelity = 0.968492190108913\n"
     ]
    }
   ],
   "source": [
    "test(H, mdl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### grad H.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward = 0.5031310481583539 enery= -1.015592062560785 rejection rate = 0.045454545454545456\n",
      "reward = 0.3410032525492095 enery= -0.8679898432978174 rejection rate = 0.28\n",
      "reward = 0.5975525133949598 enery= -1.333036661698833 rejection rate = 0.17\n",
      "reward = 0.23273667078476007 enery= -0.4864008781593779 rejection rate = 0.49\n",
      "reward = -0.06439309001222317 enery= 0.4440902759463659 rejection rate = 0.71\n",
      "reward = -0.0739680909603749 enery= 0.4772134900669352 rejection rate = 0.69\n",
      "reward = -0.1017793209898603 enery= 0.49648449263346406 rejection rate = 0.59\n",
      "reward = -0.07445820415632083 enery= 0.49638802770880547 rejection rate = 0.7\n",
      "reward = -0.06946998145447696 enery= 0.4962141532462639 rejection rate = 0.72\n",
      "reward = -0.08184154702141253 enery= 0.4960093758873475 rejection rate = 0.67\n",
      "reward = -0.05949179458186245 enery= 0.4957649548488536 rejection rate = 0.76\n",
      "reward = -0.09434194508332251 enery= 0.4965365530701172 rejection rate = 0.62\n",
      "reward = -0.08688432118468362 enery= 0.49648183534105017 rejection rate = 0.65\n",
      "reward = -0.10195522509023515 enery= 0.4973425614157824 rejection rate = 0.59\n",
      "reward = -0.07458075069972683 enery= 0.4972050046648468 rejection rate = 0.7\n",
      "reward = -0.07207092280528395 enery= 0.4970408469329918 rejection rate = 0.71\n",
      "reward = -0.09440195115874564 enery= 0.49685237451971354 rejection rate = 0.62\n",
      "reward = -0.08483485527862233 enery= 0.4990285604624844 rejection rate = 0.66\n",
      "reward = -0.0823376556841391 enery= 0.4990160950553885 rejection rate = 0.67\n",
      "reward = -0.09980010394836036 enery= 0.4990005197418007 rejection rate = 0.6\n",
      "reward = -0.08482746774127053 enery= 0.4989851043604148 rejection rate = 0.66\n",
      "reward = -0.08731945122889362 enery= 0.49896829273653504 rejection rate = 0.65\n",
      "reward = -0.09729527773149088 enery= 0.49895014221277506 rejection rate = 0.61\n",
      "reward = -0.08232347898045676 enery= 0.4989301756391315 rejection rate = 0.67\n",
      "reward = -0.09728715362776091 enery= 0.4989084801423633 rejection rate = 0.61\n",
      "reward = -0.08730470045140501 enery= 0.4988840025794582 rejection rate = 0.65\n",
      "reward = -0.0798170944498051 enery= 0.4988568403112831 rejection rate = 0.68\n",
      "reward = -0.10225960809519313 enery= 0.49882735656191796 rejection rate = 0.59\n",
      "reward = -0.11222890935720053 enery= 0.4987951526986691 rejection rate = 0.55\n",
      "reward = -0.11969817292298726 enery= 0.4987423871791136 rejection rate = 0.52\n",
      "reward = -0.0922596816753019 enery= 0.4987009820286588 rejection rate = 0.63\n"
     ]
    }
   ],
   "source": [
    "mdl = VariationalModel(1)\n",
    "H = -0.2* mdl.lattice.Ht + mdl.lattice.HJ\n",
    "state = mdl.MCrun(steps=10).reset()\n",
    "optimizer = torch.optim.Adam(mdl.parameters(), lr=0.01)\n",
    "\n",
    "for iteration in range(3000):\n",
    "    rwd, Hval, state = mdl.MCrun_pg(H=H, state=state, steps=100)\n",
    "    loss = rwd\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if iteration % 99 ==0:\n",
    "        print('reward =', - loss.item(),'enery=', Hval.item(), 'rejection rate =',mdl._rejects/mdl._step)\n",
    "    mdl.reset()\n",
    "    state.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3] -0.010493961680744426\n",
      "[0, 1, 2, 7] -0.0011600090590666633\n",
      "[0, 1, 3, 6] 0.0011600090590666635\n",
      "[0, 1, 6, 7] -0.0008322284617255295\n",
      "[0, 2, 3, 5] -0.001160009059066664\n",
      "[0, 2, 5, 7] 0.7068418414644718\n",
      "[0, 3, 4, 7] 0.004836451591053823\n",
      "[0, 3, 5, 6] -0.015330413271798253\n",
      "[0, 5, 6, 7] -0.0011600090590666635\n",
      "[1, 2, 3, 4] 0.001160009059066663\n",
      "[1, 2, 4, 7] -0.015330413271798246\n",
      "[1, 2, 5, 6] 0.004836451591053823\n",
      "[1, 3, 4, 6] 0.7068418414644715\n",
      "[1, 4, 6, 7] 0.001160009059066663\n",
      "[2, 3, 4, 5] -0.0008322284617255297\n",
      "[2, 4, 5, 7] -0.0011600090590666635\n",
      "[3, 4, 5, 6] 0.0011600090590666635\n",
      "[4, 5, 6, 7] -0.010493961680744427\n",
      "energy = 0.49634762930828585 normalization factor = 0.04386413685930455\n"
     ]
    }
   ],
   "source": [
    "test(H, mdl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### bias optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward = 0.0004090446690048303 enery= -0.8719595949289324 rejection rate = 0.1\n",
      "reward = 0.0268680122309219 enery= -1.1337494141996383 rejection rate = 0.34\n",
      "reward = 0.06891436488064462 enery= -1.5359247869445527 rejection rate = 0.05\n",
      "reward = 0.07417002268440549 enery= -1.4672237869113252 rejection rate = 0.11\n",
      "reward = 0.08050424545559491 enery= -1.5683835813596678 rejection rate = 0.04\n",
      "reward = 0.0808905209285094 enery= -1.552574083469712 rejection rate = 0.06\n",
      "reward = 0.07837292595576127 enery= -1.4825536424158392 rejection rate = 0.12\n",
      "reward = 0.0856239983271111 enery= -1.5352223332295742 rejection rate = 0.03\n",
      "reward = 0.08607139541738514 enery= -1.474024983032503 rejection rate = 0.05\n",
      "reward = 0.08374751235028116 enery= -1.4735711558701565 rejection rate = 0.08\n",
      "reward = 0.0847007653603649 enery= -1.5138393011572666 rejection rate = 0.06\n",
      "reward = 0.08854459708325438 enery= -1.4858732907351577 rejection rate = 0.03\n",
      "reward = 0.08705781573502591 enery= -1.5117136609961435 rejection rate = 0.04\n",
      "reward = 0.08815237922166229 enery= -1.480628219793717 rejection rate = 0.04\n",
      "reward = 0.0890039608459978 enery= -1.4884907000820218 rejection rate = 0.03\n",
      "reward = 0.08570758851072252 enery= -1.4802811554263657 rejection rate = 0.07\n",
      "reward = 0.087403219426077 enery= -1.5211519689988984 rejection rate = 0.04\n",
      "reward = 0.08811538876941803 enery= -1.5005930291578036 rejection rate = 0.04\n",
      "reward = 0.08823510089105673 enery= -1.4998006356292817 rejection rate = 0.04\n",
      "reward = 0.08829343901447378 enery= -1.5001606246220396 rejection rate = 0.04\n",
      "reward = 0.08548165114733615 enery= -1.504934364599187 rejection rate = 0.07\n",
      "reward = 0.08997855107078453 enery= -1.511206041345112 rejection rate = 0.02\n",
      "reward = 0.09044886230182589 enery= -1.4982549537159053 rejection rate = 0.02\n",
      "reward = 0.08704882938113898 enery= -1.4899875182009752 rejection rate = 0.06\n",
      "reward = 0.08845898224205699 enery= -1.5072399192410426 rejection rate = 0.04\n",
      "reward = 0.08875118544714536 enery= -1.498724312603417 rejection rate = 0.04\n",
      "reward = 0.08704237234789503 enery= -1.4958796891103432 rejection rate = 0.06\n",
      "reward = 0.08984081990879293 enery= -1.4972964465678542 rejection rate = 0.03\n",
      "reward = 0.09097916768082864 enery= -1.4918028031271577 rejection rate = 0.02\n",
      "reward = 0.08736525474642537 enery= -1.4895056690333452 rejection rate = 0.06\n",
      "reward = 0.08530851370187201 enery= -1.497571089976601 rejection rate = 0.08\n"
     ]
    }
   ],
   "source": [
    "mdl = VariationalModel(1)\n",
    "H = -0.2* mdl.lattice.Ht + mdl.lattice.HJ\n",
    "state = mdl.MCrun(steps=10).reset()\n",
    "optimizer = torch.optim.Adam(mdl.parameters(), lr=0.01)\n",
    "\n",
    "for iteration in range(3000):\n",
    "    rwd, Hval, state = mdl.MCrun_pg(H=H, state=state, steps=100)\n",
    "    loss = rwd\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if iteration % 99 ==0:\n",
    "        print('reward =', - loss.item(),'enery=', Hval.item(), 'rejection rate =',mdl._rejects/mdl._step)\n",
    "    mdl.reset()\n",
    "    state.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3] 0.005606794366289215\n",
      "[0, 1, 2, 7] 1.2888889483116284e-10\n",
      "[0, 1, 3, 6] -1.288888948311629e-10\n",
      "[0, 1, 6, 7] 2.5190504050614362e-05\n",
      "[0, 2, 3, 5] 1.288888948311629e-10\n",
      "[0, 2, 5, 7] -2.7472915156009086e-07\n",
      "[0, 3, 4, 7] -0.49717302483631626\n",
      "[0, 3, 5, 6] 0.5027798192026056\n",
      "[0, 5, 6, 7] 1.288888948311629e-10\n",
      "[1, 2, 3, 4] -1.288888948311629e-10\n",
      "[1, 2, 4, 7] 0.5027798192026056\n",
      "[1, 2, 5, 6] -0.4971730248363165\n",
      "[1, 3, 4, 6] -2.7472915156009086e-07\n",
      "[1, 4, 6, 7] -1.288888948311629e-10\n",
      "[2, 3, 4, 5] 2.5190504050614362e-05\n",
      "[2, 4, 5, 7] 1.288888948311629e-10\n",
      "[3, 4, 5, 6] -1.288888948311629e-10\n",
      "[4, 5, 6, 7] 0.00560679436628922\n",
      "energy = -1.4998428175903764 normalization factor = 0.24714552617589042\n"
     ]
    }
   ],
   "source": [
    "test(H, mdl) # print H.eval(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Stochastic Reconfiguration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 100 steps, 500 taining loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj = 0.037870017183530766 energy = -1.151449926937054 rejection rate = 0.13636363636363635\n",
      "obj = -0.11800194885780706 energy = -1.2780598525611575 rejection rate = 0.16\n",
      "obj = 0.018226566768772264 energy = -1.8613020170980936 rejection rate = 0.06\n",
      "obj = -0.13839298192271743 energy = -1.4797356454967079 rejection rate = 0.17\n",
      "obj = 0.025310907323700286 energy = -1.5784050980209838 rejection rate = 0.08\n",
      "obj = -0.08096803498495703 energy = -1.489909874651052 rejection rate = 0.24\n",
      "obj = 0.011871325093821343 energy = -1.5728619111253836 rejection rate = 0.11\n",
      "obj = 0.00828138441755178 energy = -1.5244338895534453 rejection rate = 0.11\n",
      "obj = 0.015777519103283632 energy = -1.486390753372354 rejection rate = 0.15\n",
      "obj = -0.13933289936303817 energy = -1.5419745292066551 rejection rate = 0.06\n",
      "obj = -0.10601282341245387 energy = -1.5495272714673536 rejection rate = 0.07\n",
      "seconds = 67.82742404937744\n",
      "[0, 1, 2, 3] 0.0715573865757192\n",
      "[0, 1, 2, 7] 0.0872030876513947\n",
      "[0, 1, 3, 6] -0.08720308765139474\n",
      "[0, 1, 6, 7] 0.05524341504710048\n",
      "[0, 2, 3, 5] 0.0872030876513947\n",
      "[0, 2, 5, 7] -0.03178678431677791\n",
      "[0, 3, 4, 7] -0.44267692748206344\n",
      "[0, 3, 5, 6] 0.5142343140577826\n",
      "[0, 5, 6, 7] 0.0872030876513947\n",
      "[1, 2, 3, 4] -0.0872030876513947\n",
      "[1, 2, 4, 7] 0.5142343140577825\n",
      "[1, 2, 5, 6] -0.4426769274820635\n",
      "[1, 3, 4, 6] -0.03178678431677792\n",
      "[1, 4, 6, 7] -0.08720308765139467\n",
      "[2, 3, 4, 5] 0.055243415047100466\n",
      "[2, 4, 5, 7] 0.08720308765139467\n",
      "[3, 4, 5, 6] -0.08720308765139474\n",
      "[4, 5, 6, 7] 0.07155738657571914\n",
      "energy = -1.5576989309287517 normalization factor = 0.01615464269331999 fidelity = 0.9838666132889026\n"
     ]
    }
   ],
   "source": [
    "mdl = VariationalModel(1)\n",
    "H = -0.2* mdl.lattice.Ht + mdl.lattice.HJ\n",
    "state = mdl.MCrun(steps=10).reset()\n",
    "optimizer = torch.optim.Adam(mdl.parameters(), lr=0.01)\n",
    "start = time.time()\n",
    "for iteration in range(500):\n",
    "    obj, Hval, state = mdl.MCrun_sr(H=H, state=state, steps=100)\n",
    "    loss = obj #- Hval.detach()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if iteration%49 ==0:\n",
    "        print('obj =', loss.item(), 'energy =', Hval.item(), 'rejection rate =',mdl._rejects/mdl._step)\n",
    "    mdl.reset()\n",
    "    state.reset()\n",
    "end = time.time()\n",
    "print('seconds =',end - start)\n",
    "test(H, mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj = -0.4287709134747836 energy = -0.8877636354360388 rejection rate = 0.045454545454545456\n",
      "obj = -0.5073003989518441 energy = -1.1100572957075778 rejection rate = 0.11\n",
      "obj = -0.6354606826205813 energy = -1.4714564705722335 rejection rate = 0.15\n",
      "obj = -0.825548089754977 energy = -1.7755130351793047 rejection rate = 0.09\n",
      "obj = -0.6718671134492595 energy = -1.5460483193373848 rejection rate = 0.13\n",
      "obj = -0.6653442218322294 energy = -1.4950409290084483 rejection rate = 0.16\n",
      "obj = -0.7468078599812356 energy = -1.6264000776630925 rejection rate = 0.08\n",
      "obj = -0.7366311200984712 energy = -1.6058596363902302 rejection rate = 0.09\n",
      "obj = -0.66208505443296 energy = -1.5334194969951387 rejection rate = 0.13\n",
      "obj = -0.6980662579034632 energy = -1.5584504021013226 rejection rate = 0.12\n",
      "obj = -0.7821197047135432 energy = -1.693645932206653 rejection rate = 0.08\n",
      "seconds 69.633780002594\n",
      "[0, 1, 2, 3] 0.08748984891652724\n",
      "[0, 1, 2, 7] 0.09980716246993103\n",
      "[0, 1, 3, 6] -0.09980716246993108\n",
      "[0, 1, 6, 7] 0.06597627954479648\n",
      "[0, 2, 3, 5] 0.09980716246993103\n",
      "[0, 2, 5, 7] -0.042208355969569844\n",
      "[0, 3, 4, 7] -0.4266474628140117\n",
      "[0, 3, 5, 6] 0.5141373117305392\n",
      "[0, 5, 6, 7] 0.09980716246993103\n",
      "[1, 2, 3, 4] -0.09980716246993113\n",
      "[1, 2, 4, 7] 0.514137311730539\n",
      "[1, 2, 5, 6] -0.4266474628140122\n",
      "[1, 3, 4, 6] -0.04220835596956989\n",
      "[1, 4, 6, 7] -0.09980716246993103\n",
      "[2, 3, 4, 5] 0.06597627954479648\n",
      "[2, 4, 5, 7] 0.09980716246993103\n",
      "[3, 4, 5, 6] -0.09980716246993108\n",
      "[4, 5, 6, 7] 0.0874898489165272\n",
      "energy = -1.5487069673453673 normalization factor = 0.01484438284564035 fidelity = 0.9773578663705839\n"
     ]
    }
   ],
   "source": [
    "mdl = VariationalModel(1)\n",
    "H = -0.2* mdl.lattice.Ht + mdl.lattice.HJ\n",
    "state = mdl.MCrun(steps=10).reset()\n",
    "optimizer = torch.optim.Adam(mdl.parameters(), lr=0.01)\n",
    "start = time.time()\n",
    "for iteration in range(500):\n",
    "    obj, Hval, state = mdl.MCrun_pg(H=H, state=state, steps=100)\n",
    "    loss = obj\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if iteration%49 ==0:\n",
    "        print('obj =', loss.item(), 'energy =', Hval.item(), 'rejection rate =',mdl._rejects/mdl._step)\n",
    "    mdl.reset()\n",
    "    state.reset()\n",
    "end = time.time()\n",
    "print('seconds',end - start)\n",
    "test(H, mdl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1000 steps, 100 training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj = 0.021748832306537666 energy = -0.9733709514213379 rejection rate = 0.0891089108910891\n",
      "obj = 0.029406418148428225 energy = -1.1773747314037954 rejection rate = 0.071\n",
      "obj = -0.04241790061398064 energy = -1.1621397601912415 rejection rate = 0.132\n",
      "obj = -0.0938374932172493 energy = -1.301332445139461 rejection rate = 0.159\n",
      "obj = -0.10684488523296244 energy = -1.4341319298507544 rejection rate = 0.136\n",
      "obj = -0.08448558370214822 energy = -1.4685987409746897 rejection rate = 0.16\n",
      "obj = -0.1128438075764028 energy = -1.3818987714798239 rejection rate = 0.15\n",
      "obj = -0.0977876448765299 energy = -1.579470547310811 rejection rate = 0.12\n",
      "obj = -0.05869450184129363 energy = -1.4454148134581848 rejection rate = 0.174\n",
      "obj = -0.07953152363777397 energy = -1.5004188195624852 rejection rate = 0.168\n",
      "obj = -0.04577502618158632 energy = -1.4997838743382912 rejection rate = 0.158\n",
      "obj = -0.08177418755137811 energy = -1.567493787775867 rejection rate = 0.147\n",
      "seconds = 137.53303980827332\n",
      "[0, 1, 2, 3] 0.12499794645381121\n",
      "[0, 1, 2, 7] 0.10773236189113689\n",
      "[0, 1, 3, 6] -0.10773236189113698\n",
      "[0, 1, 6, 7] 0.12560855884795075\n",
      "[0, 2, 3, 5] 0.10773236189113694\n",
      "[0, 2, 5, 7] -0.05307797532805373\n",
      "[0, 3, 4, 7] -0.39112170606259666\n",
      "[0, 3, 5, 6] 0.516119652516408\n",
      "[0, 5, 6, 7] 0.10773236189113689\n",
      "[1, 2, 3, 4] -0.10773236189113698\n",
      "[1, 2, 4, 7] 0.516119652516408\n",
      "[1, 2, 5, 6] -0.39112170606259666\n",
      "[1, 3, 4, 6] -0.0530779753280538\n",
      "[1, 4, 6, 7] -0.10773236189113694\n",
      "[2, 3, 4, 5] 0.12560855884795077\n",
      "[2, 4, 5, 7] 0.10773236189113689\n",
      "[3, 4, 5, 6] -0.10773236189113694\n",
      "[4, 5, 6, 7] 0.12499794645381117\n",
      "energy = -1.5066229999277434 normalization factor = 0.01507827793971076 fidelity = 0.9580584406598597\n"
     ]
    }
   ],
   "source": [
    "mdl = VariationalModel(1)\n",
    "H = -0.2* mdl.lattice.Ht + mdl.lattice.HJ\n",
    "state = mdl.MCrun(steps=10).reset()\n",
    "optimizer = torch.optim.Adam(mdl.parameters(), lr=0.01)\n",
    "start = time.time()\n",
    "for iteration in range(100):\n",
    "    obj, Hval, state = mdl.MCrun_sr(H=H, state=state, steps=1000)\n",
    "    loss = obj #- Hval.detach()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if iteration%9 ==0:\n",
    "        print('obj =', loss.item(), 'energy =', Hval.item(), 'rejection rate =',mdl._rejects/mdl._step)\n",
    "    mdl.reset()\n",
    "    state.reset()\n",
    "end = time.time()\n",
    "print('seconds =',end - start)\n",
    "test(H, mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj = -0.49402935264914716 energy = -1.0381724666115029 rejection rate = 0.07227722772277227\n",
      "obj = -0.5002273894210174 energy = -1.1107785447455116 rejection rate = 0.102\n",
      "obj = -0.5548608119185343 energy = -1.2077565096494354 rejection rate = 0.096\n",
      "obj = -0.5812055456346633 energy = -1.2886294342914864 rejection rate = 0.128\n",
      "obj = -0.6310886865182672 energy = -1.4160953446227207 rejection rate = 0.137\n",
      "obj = -0.600655476347467 energy = -1.3824044190062401 rejection rate = 0.156\n",
      "obj = -0.5825110005010444 energy = -1.34342205961877 rejection rate = 0.158\n",
      "obj = -0.6090960979479609 energy = -1.3871834991195424 rejection rate = 0.144\n",
      "obj = -0.6217290052757238 energy = -1.429735243456281 rejection rate = 0.155\n",
      "obj = -0.651942891862603 energy = -1.4560063605496782 rejection rate = 0.124\n",
      "obj = -0.6127523036802274 energy = -1.4007818322352903 rejection rate = 0.156\n",
      "obj = -0.6811740305445824 energy = -1.5249823486843357 rejection rate = 0.126\n",
      "seconds 142.13578987121582\n",
      "[0, 1, 2, 3] 0.13652824677282405\n",
      "[0, 1, 2, 7] 0.14502324895872154\n",
      "[0, 1, 3, 6] -0.14502324895872162\n",
      "[0, 1, 6, 7] 0.14583159201402668\n",
      "[0, 2, 3, 5] 0.14502324895872162\n",
      "[0, 2, 5, 7] -0.0745089667236689\n",
      "[0, 3, 4, 7] -0.3566444823419025\n",
      "[0, 3, 5, 6] 0.4931727291147267\n",
      "[0, 5, 6, 7] 0.14502324895872162\n",
      "[1, 2, 3, 4] -0.14502324895872162\n",
      "[1, 2, 4, 7] 0.49317272911472654\n",
      "[1, 2, 5, 6] -0.35664448234190277\n",
      "[1, 3, 4, 6] -0.07450896672366887\n",
      "[1, 4, 6, 7] -0.14502324895872162\n",
      "[2, 3, 4, 5] 0.1458315920140267\n",
      "[2, 4, 5, 7] 0.14502324895872162\n",
      "[3, 4, 5, 6] -0.14502324895872168\n",
      "[4, 5, 6, 7] 0.13652824677282405\n",
      "energy = -1.4628948764345133 normalization factor = 0.011646603777669927 fidelity = 0.9239653932794047\n"
     ]
    }
   ],
   "source": [
    "mdl = VariationalModel(1)\n",
    "H = -0.2* mdl.lattice.Ht + mdl.lattice.HJ\n",
    "state = mdl.MCrun(steps=10).reset()\n",
    "optimizer = torch.optim.Adam(mdl.parameters(), lr=0.01)\n",
    "start = time.time()\n",
    "for iteration in range(100):\n",
    "    obj, Hval, state = mdl.MCrun_pg(H=H, state=state, steps=1000)\n",
    "    loss = obj #- Hval.detach()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if iteration%9 ==0:\n",
    "        print('obj =', loss.item(), 'energy =', Hval.item(), 'rejection rate =',mdl._rejects/mdl._step)\n",
    "    mdl.reset()\n",
    "    state.reset()\n",
    "end = time.time()\n",
    "print('seconds',end - start)\n",
    "test(H, mdl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### biased without '-Hval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj = 8.195200874574986 energy = -1.0431656556895925 rejection rate = 0.1\n",
      "obj = 7.04801992627338 energy = -1.2212958364148483 rejection rate = 0.28\n",
      "obj = 6.416489911080817 energy = -1.4401023263555737 rejection rate = 0.26\n",
      "obj = 6.549591906636346 energy = -1.6631599869082538 rejection rate = 0.11\n",
      "obj = 4.081246467802258 energy = -1.2803291869179814 rejection rate = 0.22\n",
      "obj = 4.718536866201032 energy = -1.4589237700174118 rejection rate = 0.11\n",
      "obj = 4.683637082053294 energy = -1.4838090382936886 rejection rate = 0.15\n",
      "obj = 4.726504461681505 energy = -1.516078546627182 rejection rate = 0.12\n",
      "obj = 3.425439461571637 energy = -1.1278420549780206 rejection rate = 0.33\n",
      "obj = 4.985211095549612 energy = -1.6012916365774807 rejection rate = 0.09\n",
      "obj = 4.449459664993982 energy = -1.4927941902719428 rejection rate = 0.09\n",
      "seconds = 69.96335101127625\n",
      "[0, 1, 2, 3] 0.05855015221772714\n",
      "[0, 1, 2, 7] 2.1742918942620318e-05\n",
      "[0, 1, 3, 6] -2.174291894262031e-05\n",
      "[0, 1, 6, 7] 0.005832226553862655\n",
      "[0, 2, 3, 5] 2.174291894262031e-05\n",
      "[0, 2, 5, 7] -0.0007179733999562938\n",
      "[0, 3, 4, 7] -0.46812983302931765\n",
      "[0, 3, 5, 6] 0.5266799852470447\n",
      "[0, 5, 6, 7] 2.174291894262031e-05\n",
      "[1, 2, 3, 4] -2.1742918942620318e-05\n",
      "[1, 2, 4, 7] 0.5266799852470448\n",
      "[1, 2, 5, 6] -0.4681298330293177\n",
      "[1, 3, 4, 6] -0.0007179733999562938\n",
      "[1, 4, 6, 7] -2.174291894262031e-05\n",
      "[2, 3, 4, 5] 0.005832226553862655\n",
      "[2, 4, 5, 7] 2.174291894262031e-05\n",
      "[3, 4, 5, 6] -2.174291894262031e-05\n",
      "[4, 5, 6, 7] 0.05855015221772711\n",
      "energy = -1.4827964606619293 normalization factor = 0.20588820663714594 fidelity = 0.972565929005378\n"
     ]
    }
   ],
   "source": [
    "mdl = VariationalModel(1)\n",
    "H = -0.2* mdl.lattice.Ht + mdl.lattice.HJ\n",
    "state = mdl.MCrun(steps=10).reset()\n",
    "optimizer = torch.optim.Adam(mdl.parameters(), lr=0.01)\n",
    "start = time.time()\n",
    "for iteration in range(500):\n",
    "    obj, Hval, state = mdl.MCrun_sr(H=H, state=state, steps=100)\n",
    "    loss = obj #- Hval.detach()\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if iteration%49 ==0:\n",
    "        print('obj =', loss.item(), 'energy =', Hval.item(), 'rejection rate =',mdl._rejects/mdl._step)\n",
    "    mdl.reset()\n",
    "    state.reset()\n",
    "end = time.time()\n",
    "print('seconds =',end - start)\n",
    "test(H, mdl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
